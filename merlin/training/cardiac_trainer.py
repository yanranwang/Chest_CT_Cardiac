import os
import json
import time
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torch.utils.tensorboard import SummaryWriter
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import train_test_split
import monai
from monai.losses import DiceLoss
from monai.transforms import Compose
import logging
from pathlib import Path
from tqdm import tqdm
import warnings

# æŠ‘åˆ¶ä¸å¿…è¦çš„è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)

from merlin.models.cardiac_regression import CardiacFunctionModel, CardiacMetricsCalculator
from merlin.data.dataloaders import CTPersistentDataset
from merlin.data.monai_transforms import ImageTransforms


class CardiacDataset(Dataset):
    """å¿ƒè„åŠŸèƒ½æ•°æ®é›† - æ”¯æŒä»CSVæ–‡ä»¶è¯»å–æ•°æ®"""
    def __init__(self, data_list, transform=None, cardiac_metric_columns=None):
        self.data_list = data_list
        self.transform = transform or ImageTransforms
        self.cardiac_metric_columns = cardiac_metric_columns or []
        self.metric_names = CardiacMetricsCalculator.get_metric_names()
    
    def __len__(self):
        return len(self.data_list)
    
    def __getitem__(self, idx):
        sample = self.data_list[idx]
        
        # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
        if self.transform:
            sample = self.transform(sample)
        
        # è·å–å¿ƒè„åŠŸèƒ½æ ‡ç­¾
        if 'cardiac_metrics' in sample and sample['cardiac_metrics'] is not None:
            cardiac_metrics = torch.tensor(sample['cardiac_metrics'], dtype=torch.float32)
        else:
            # å¦‚æœæ²¡æœ‰çœŸå®æ ‡ç­¾ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
            cardiac_metrics = torch.tensor(self._generate_dummy_labels(), dtype=torch.float32)
        
        # ç¡®ä¿æ ‡ç­¾åŒ…å«LVEFå’ŒASä¸¤ä¸ªå€¼
        if len(cardiac_metrics) < 2:
            # å¦‚æœæ ‡ç­¾æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®
            cardiac_metrics = torch.tensor(self._generate_dummy_labels(), dtype=torch.float32)
        
        return {
            'image': sample['image'],
            'cardiac_metrics': cardiac_metrics,
            'patient_id': sample.get('patient_id', f'patient_{idx}'),
            'basename': sample.get('basename', f'unknown_{idx}'),
            'folder': sample.get('folder', 'unknown'),
            'image_path': sample.get('image', ''),
            'metadata': sample.get('metadata', {})
        }
    
    def _generate_dummy_labels(self):
        """ç”Ÿæˆæ¨¡æ‹Ÿçš„å¿ƒè„åŠŸèƒ½æ ‡ç­¾ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        # ç”ŸæˆLVEFå’ŒASçš„æ¨¡æ‹Ÿæ•°æ®
        # LVEF: æ­£å¸¸èŒƒå›´çº¦50-70%ï¼Œè¿™é‡Œç”Ÿæˆæ ‡å‡†åŒ–å€¼
        lvef = np.float32(np.random.normal(0, 1))
        # AS: äºŒåˆ†ç±»ï¼Œ0æˆ–1
        as_label = np.float32(np.random.randint(0, 2))
        
        return np.array([lvef, as_label], dtype=np.float32)


class CardiacTrainer:
    """å¿ƒè„åŠŸèƒ½å›å½’è®­ç»ƒå™¨"""
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device(config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu'))
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(config['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—ï¼ˆå¿…é¡»åœ¨ä½¿ç”¨loggerä¹‹å‰ï¼‰
        self._setup_logging()
        
        # è®¾ç½®éšæœºç§å­
        self._set_random_seed(config.get('seed', 42))
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = self._build_model()
        
        # åˆå§‹åŒ–ä¼˜åŒ–å™¨å’Œè°ƒåº¦å™¨
        self.optimizer = self._build_optimizer()
        self.scheduler = self._build_scheduler()
        
        # åˆå§‹åŒ–æŸå¤±å‡½æ•°
        self.criterion = self._build_loss_function()
        
        # åˆå§‹åŒ–è®­ç»ƒè®°å½•
        self.best_val_loss = float('inf')
        self.train_losses = []
        self.val_losses = []
        self.epoch_times = []
        
        # åˆå§‹åŒ–tensorboardè®°å½•å™¨
        if config.get('use_tensorboard', True):
            self.writer = SummaryWriter(self.output_dir / 'tensorboard')
        else:
            self.writer = None
    
    def _set_random_seed(self, seed):
        """è®¾ç½®éšæœºç§å­"""
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        np.random.seed(seed)
    
    def _build_model(self):
        """æ„å»ºæ¨¡å‹"""
        model = CardiacFunctionModel(
            pretrained_model_path=self.config.get('pretrained_model_path')
        )
        
        # æ˜¯å¦å†»ç»“å›¾åƒç¼–ç å™¨
        if self.config.get('freeze_encoder', False):
            model.freeze_encoder(True)
            self.logger.info("å›¾åƒç¼–ç å™¨å·²å†»ç»“")
        
        model = model.to(self.device)
        
        # å¤šGPUè®­ç»ƒ
        if torch.cuda.device_count() > 1:
            # æ£€æŸ¥batch_sizeæ˜¯å¦è¶³å¤Ÿå¤§ï¼Œé¿å…æ¯ä¸ªGPUåˆ†åˆ°çš„batch_sizeä¸º1
            batch_size = self.config.get('batch_size', 4)
            num_gpus = torch.cuda.device_count()
            if batch_size < num_gpus:
                self.logger.warning(f"æ‰¹é‡å¤§å° {batch_size} å°äºGPUæ•°é‡ {num_gpus}ï¼Œå¯èƒ½å¯¼è‡´BatchNormé”™è¯¯")
                self.logger.warning("å»ºè®®å¢åŠ æ‰¹é‡å¤§å°æˆ–å‡å°‘GPUæ•°é‡")
            
            model = nn.DataParallel(model)
            self.logger.info(f"ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPUè¿›è¡Œè®­ç»ƒ")
        
        return model
    
    def _build_optimizer(self):
        """æ„å»ºä¼˜åŒ–å™¨"""
        optimizer_name = self.config.get('optimizer', 'adam').lower()
        lr = self.config.get('learning_rate', 1e-4)
        weight_decay = self.config.get('weight_decay', 1e-5)
        
        if optimizer_name == 'adam':
            optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)
        elif optimizer_name == 'adamw':
            optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)
        elif optimizer_name == 'sgd':
            optimizer = optim.SGD(self.model.parameters(), lr=lr, weight_decay=weight_decay, momentum=0.9)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–å™¨: {optimizer_name}")
        
        return optimizer
    
    def _build_scheduler(self):
        """æ„å»ºå­¦ä¹ ç‡è°ƒåº¦å™¨"""
        scheduler_config = self.config.get('scheduler', {})
        scheduler_type = scheduler_config.get('type', 'cosine')
        
        if scheduler_type == 'cosine':
            scheduler = optim.lr_scheduler.CosineAnnealingLR(
                self.optimizer, 
                T_max=self.config.get('epochs', 100),
                eta_min=scheduler_config.get('eta_min', 1e-6)
            )
        elif scheduler_type == 'step':
            scheduler = optim.lr_scheduler.StepLR(
                self.optimizer,
                step_size=scheduler_config.get('step_size', 30),
                gamma=scheduler_config.get('gamma', 0.1)
            )
        elif scheduler_type == 'plateau':
            scheduler = optim.lr_scheduler.ReduceLROnPlateau(
                self.optimizer,
                mode='min',
                factor=scheduler_config.get('factor', 0.5),
                patience=scheduler_config.get('patience', 10)
            )
        else:
            scheduler = None
        
        return scheduler
    
    def _build_loss_function(self):
        """æ„å»ºæŸå¤±å‡½æ•°"""
        from merlin.models.cardiac_regression import CardiacLoss
        
        # ä½¿ç”¨ä¸“é—¨çš„å¿ƒè„åŠŸèƒ½æŸå¤±å‡½æ•°ï¼Œå¤„ç†LVEFå›å½’å’ŒASåˆ†ç±»
        regression_weight = self.config.get('regression_weight', 1.0)
        classification_weight = self.config.get('classification_weight', 1.0)
        
        criterion = CardiacLoss(
            regression_weight=regression_weight,
            classification_weight=classification_weight
        )
        
        return criterion
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(self.output_dir / 'training.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def _format_time(self, seconds):
        """æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º"""
        if seconds < 60:
            return f"{seconds:.1f}s"
        elif seconds < 3600:
            minutes = seconds // 60
            secs = seconds % 60
            return f"{minutes:.0f}m {secs:.0f}s"
        else:
            hours = seconds // 3600
            minutes = (seconds % 3600) // 60
            return f"{hours:.0f}h {minutes:.0f}m"
    
    def train_epoch(self, train_loader, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        epoch_loss = 0.0
        num_batches = len(train_loader)
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1:3d}/{self.config.get("epochs", 100)}', 
                   ncols=120, leave=False)
        
        batch_losses = []
        for batch_idx, batch in enumerate(pbar):
            images = batch['image'].to(self.device)
            
            # ä»cardiac_metricsä¸­æå–LVEFå’ŒASç›®æ ‡å€¼
            cardiac_metrics = batch['cardiac_metrics'].to(self.device)
            # å‡è®¾cardiac_metricsçš„ç¬¬ä¸€ä¸ªå€¼æ˜¯LVEFï¼Œç¬¬äºŒä¸ªå€¼æ˜¯AS
            if cardiac_metrics.shape[1] >= 2:
                lvef_targets = cardiac_metrics[:, 0]  # LVEFç›®æ ‡å€¼
                as_targets = cardiac_metrics[:, 1]    # ASç›®æ ‡å€¼
            else:
                # å¦‚æœåªæœ‰ä¸€ä¸ªå€¼ï¼Œå‡è®¾æ˜¯LVEFï¼ŒASè®¾ä¸º0
                lvef_targets = cardiac_metrics[:, 0]
                as_targets = torch.zeros_like(lvef_targets)
            
            # å‰å‘ä¼ æ’­
            self.optimizer.zero_grad()
            lvef_preds, as_preds = self.model(images)
            
            # è®¡ç®—æŸå¤±
            loss_dict = self.criterion(lvef_preds, as_preds, lvef_targets, as_targets)
            loss = loss_dict['total_loss']
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            if self.config.get('grad_clip', None):
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config['grad_clip'])
            
            self.optimizer.step()
            
            epoch_loss += loss.item()
            batch_losses.append(loss.item())
            
            # æ›´æ–°è¿›åº¦æ¡
            if len(batch_losses) >= 10:  # æ˜¾ç¤ºæœ€è¿‘10ä¸ªbatchçš„å¹³å‡æŸå¤±
                recent_loss = np.mean(batch_losses[-10:])
            else:
                recent_loss = np.mean(batch_losses)
            
            pbar.set_postfix({
                'Loss': f'{recent_loss:.4f}',
                'LR': f'{self.optimizer.param_groups[0]["lr"]:.2e}',
                'GPU': f'{torch.cuda.get_device_name(0)[:12]}' if torch.cuda.is_available() else 'CPU'
            })
            
            # è¯¦ç»†æ—¥å¿—è®°å½•
            if batch_idx % max(1, self.config.get('log_interval', 10)) == 0:
                self.logger.info(
                    f'Epoch {epoch+1:3d} [{batch_idx:4d}/{num_batches:4d}] '
                    f'Loss: {loss.item():.6f} | LR: {self.optimizer.param_groups[0]["lr"]:.2e} | '
                    f'GPU Memory: {torch.cuda.memory_allocated()/1024**3:.1f}GB' 
                    if torch.cuda.is_available() else ''
                )
                
                if self.writer:
                    step = epoch * num_batches + batch_idx
                    self.writer.add_scalar('Train/BatchLoss', loss.item(), step)
                    self.writer.add_scalar('Train/LearningRate', self.optimizer.param_groups[0]['lr'], step)
        
        avg_loss = epoch_loss / num_batches
        self.train_losses.append(avg_loss)
        
        # æ¸…é™¤è¿›åº¦æ¡
        pbar.close()
        
        return avg_loss
    
    def validate_epoch(self, val_loader, epoch):
        """éªŒè¯ä¸€ä¸ªepoch"""
        self.model.eval()
        epoch_loss = 0.0
        all_predictions = []
        all_targets = []
        
        # åˆ›å»ºéªŒè¯è¿›åº¦æ¡
        pbar = tqdm(val_loader, desc=f'Validating', ncols=120, leave=False)
        
        with torch.no_grad():
            for batch in pbar:
                images = batch['image'].to(self.device)
                
                # ä»cardiac_metricsä¸­æå–LVEFå’ŒASç›®æ ‡å€¼
                cardiac_metrics = batch['cardiac_metrics'].to(self.device)
                if cardiac_metrics.shape[1] >= 2:
                    lvef_targets = cardiac_metrics[:, 0]  # LVEFç›®æ ‡å€¼
                    as_targets = cardiac_metrics[:, 1]    # ASç›®æ ‡å€¼
                else:
                    lvef_targets = cardiac_metrics[:, 0]
                    as_targets = torch.zeros_like(lvef_targets)
                
                # å‰å‘ä¼ æ’­
                lvef_preds, as_preds = self.model(images)
                
                # è®¡ç®—æŸå¤±
                loss_dict = self.criterion(lvef_preds, as_preds, lvef_targets, as_targets)
                loss = loss_dict['total_loss']
                epoch_loss += loss.item()
                
                # æ›´æ–°éªŒè¯è¿›åº¦æ¡
                pbar.set_postfix({'Val Loss': f'{loss.item():.4f}'})
                
                # æ”¶é›†é¢„æµ‹å’ŒçœŸå€¼ç”¨äºæŒ‡æ ‡è®¡ç®—
                predictions = torch.stack([lvef_preds.squeeze(), as_preds.squeeze()], dim=1)
                targets = torch.stack([lvef_targets, as_targets], dim=1)
                all_predictions.append(predictions.cpu().numpy())
                all_targets.append(targets.cpu().numpy())
        
        pbar.close()
        
        avg_loss = epoch_loss / len(val_loader)
        self.val_losses.append(avg_loss)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        all_predictions = np.concatenate(all_predictions, axis=0)
        all_targets = np.concatenate(all_targets, axis=0)
        
        metrics = self._calculate_metrics(all_predictions, all_targets)
        
        # è®°å½•éªŒè¯ç»“æœ
        self.logger.info(f'éªŒè¯ç»“æœ - Epoch {epoch+1:3d} | Loss: {avg_loss:.6f}')
        for metric_name, value in metrics.items():
            self.logger.info(f'  {metric_name}: {value:.4f}')
        
        if self.writer:
            self.writer.add_scalar('Val/Loss', avg_loss, epoch)
            for metric_name, value in metrics.items():
                self.writer.add_scalar(f'Val/{metric_name}', value, epoch)
        
        return avg_loss, metrics
    
    def _calculate_metrics(self, predictions, targets):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        
        metrics = {}
        
        # LVEFå›å½’æŒ‡æ ‡ï¼ˆç¬¬0åˆ—ï¼‰
        lvef_preds = predictions[:, 0]
        lvef_targets = targets[:, 0]
        
        metrics['LVEF_MSE'] = mean_squared_error(lvef_targets, lvef_preds)
        metrics['LVEF_MAE'] = mean_absolute_error(lvef_targets, lvef_preds)
        metrics['LVEF_R2'] = r2_score(lvef_targets, lvef_preds)
        
        # ASåˆ†ç±»æŒ‡æ ‡ï¼ˆç¬¬1åˆ—ï¼‰
        as_preds = predictions[:, 1]
        as_targets = targets[:, 1]
        
        # å°†æ¦‚ç‡è½¬æ¢ä¸ºäºŒåˆ†ç±»é¢„æµ‹
        as_pred_binary = (as_preds > 0.5).astype(int)
        as_targets_binary = as_targets.astype(int)
        
        metrics['AS_Accuracy'] = accuracy_score(as_targets_binary, as_pred_binary)
        metrics['AS_Precision'] = precision_score(as_targets_binary, as_pred_binary, zero_division=0)
        metrics['AS_Recall'] = recall_score(as_targets_binary, as_pred_binary, zero_division=0)
        metrics['AS_F1'] = f1_score(as_targets_binary, as_pred_binary, zero_division=0)
        
        # è®¡ç®—ASçš„AUC
        try:
            from sklearn.metrics import roc_auc_score
            metrics['AS_AUC'] = roc_auc_score(as_targets_binary, as_preds)
        except ValueError:
            metrics['AS_AUC'] = 0.0
        
        return metrics
    
    def save_checkpoint(self, epoch, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses,
            'best_val_loss': self.best_val_loss,
            'config': self.config
        }
        
        # ä¿å­˜æœ€æ–°æ£€æŸ¥ç‚¹
        torch.save(checkpoint, self.output_dir / 'checkpoint_latest.pth')
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            torch.save(checkpoint, self.output_dir / 'checkpoint_best.pth')
            torch.save(self.model.state_dict(), self.output_dir / 'best_model.pth')
            self.logger.info(f'ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹ (Epoch {epoch+1}, Val Loss: {self.best_val_loss:.6f})')
    
    def load_checkpoint(self, checkpoint_path):
        """åŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint = torch.load(checkpoint_path, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        if self.scheduler and checkpoint['scheduler_state_dict']:
            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        self.train_losses = checkpoint.get('train_losses', [])
        self.val_losses = checkpoint.get('val_losses', [])
        self.best_val_loss = checkpoint.get('best_val_loss', float('inf'))
        
        self.logger.info(f'ä» {checkpoint_path} åŠ è½½æ£€æŸ¥ç‚¹')
        return checkpoint['epoch']
    
    def train(self, train_loader, val_loader=None, start_epoch=0):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        epochs = self.config.get('epochs', 100)
        
        # æ‰“å°è®­ç»ƒå¼€å§‹ä¿¡æ¯
        print("=" * 80)
        print(f"ğŸš€ å¼€å§‹è®­ç»ƒå¿ƒè„åŠŸèƒ½é¢„æµ‹æ¨¡å‹")
        print("=" * 80)
        print(f"ğŸ“Š è®­ç»ƒå‚æ•°:")
        print(f"   æ€»è½®æ•°: {epochs}")
        print(f"   æ‰¹é‡å¤§å°: {self.config.get('batch_size', 4)}")
        print(f"   å­¦ä¹ ç‡: {self.config.get('learning_rate', 1e-4)}")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   ä¼˜åŒ–å™¨: {self.config.get('optimizer', 'adam')}")
        print(f"   è°ƒåº¦å™¨: {self.config.get('scheduler', {}).get('type', 'None')}")
        print(f"ğŸ“ æ•°æ®ç»Ÿè®¡:")
        print(f"   è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
        if val_loader:
            print(f"   éªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
        print(f"   æ¯è½®æ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {self.output_dir}")
        if self.writer:
            print(f"ğŸ“ˆ TensorBoard: {self.output_dir / 'tensorboard'}")
        print("=" * 80)
        
        self.logger.info(f'å¼€å§‹è®­ç»ƒï¼Œå…± {epochs} ä¸ªepoch')
        
        # è®­ç»ƒå¼€å§‹æ—¶é—´
        training_start_time = time.time()
        
        for epoch in range(start_epoch, epochs):
            epoch_start_time = time.time()
            
            # æ‰“å°epochå¼€å§‹ä¿¡æ¯
            print(f"\nğŸ”„ Epoch {epoch+1}/{epochs}")
            print("-" * 50)
            
            # è®­ç»ƒ
            train_loss = self.train_epoch(train_loader, epoch)
            
            # éªŒè¯
            val_loss, val_metrics = None, {}
            if val_loader:
                val_loss, val_metrics = self.validate_epoch(val_loader, epoch)
                
                # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨
                if self.scheduler:
                    if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                        self.scheduler.step(val_loss)
                    else:
                        self.scheduler.step()
                
                # æ£€æŸ¥æ˜¯å¦ä¸ºæœ€ä½³æ¨¡å‹
                is_best = val_loss < self.best_val_loss
                if is_best:
                    improvement = self.best_val_loss - val_loss
                    self.best_val_loss = val_loss
                    print(f"âœ¨ æ–°çš„æœ€ä½³æ¨¡å‹ï¼éªŒè¯æŸå¤±é™ä½äº† {improvement:.6f}")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                if epoch % self.config.get('save_interval', 10) == 0 or is_best:
                    self.save_checkpoint(epoch, is_best)
            else:
                # æ— éªŒè¯é›†æ—¶
                if self.scheduler and not isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):
                    self.scheduler.step()
                
                if epoch % self.config.get('save_interval', 10) == 0:
                    self.save_checkpoint(epoch)
            
            # è®¡ç®—æ—¶é—´
            epoch_time = time.time() - epoch_start_time
            self.epoch_times.append(epoch_time)
            
            # é¢„ä¼°å‰©ä½™æ—¶é—´
            avg_epoch_time = np.mean(self.epoch_times[-10:])  # ä½¿ç”¨æœ€è¿‘10ä¸ªepochçš„å¹³å‡æ—¶é—´
            remaining_epochs = epochs - epoch - 1
            estimated_remaining_time = avg_epoch_time * remaining_epochs
            
            # æ‰“å°epochæ€»ç»“
            print(f"ğŸ“Š Epoch {epoch+1} æ€»ç»“:")
            print(f"   è®­ç»ƒæŸå¤±: {train_loss:.6f}")
            if val_loss is not None:
                print(f"   éªŒè¯æŸå¤±: {val_loss:.6f}")
                print(f"   LVEF RÂ²: {val_metrics.get('LVEF_R2', 0):.4f}")
                print(f"   AS å‡†ç¡®ç‡: {val_metrics.get('AS_Accuracy', 0):.4f}")
            print(f"   è½®æ¬¡è€—æ—¶: {self._format_time(epoch_time)}")
            print(f"   å¹³å‡è€—æ—¶: {self._format_time(avg_epoch_time)}")
            print(f"   é¢„ä¼°å‰©ä½™: {self._format_time(estimated_remaining_time)}")
            print(f"   å½“å‰å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.2e}")
            
            # è®°å½•åˆ°tensorboard
            if self.writer:
                self.writer.add_scalar('Train/EpochLoss', train_loss, epoch)
                self.writer.add_scalar('Train/EpochTime', epoch_time, epoch)
                if val_loader:
                    self.writer.add_scalar('Val/EpochLoss', val_loss, epoch)
        
        # è®­ç»ƒå®Œæˆ
        total_training_time = time.time() - training_start_time
        
        print("\n" + "=" * 80)
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
        print("=" * 80)
        print(f"ğŸ“ˆ è®­ç»ƒç»Ÿè®¡:")
        print(f"   æ€»è®­ç»ƒæ—¶é—´: {self._format_time(total_training_time)}")
        print(f"   å¹³å‡æ¯è½®æ—¶é—´: {self._format_time(np.mean(self.epoch_times))}")
        print(f"   æœ€ä½³éªŒè¯æŸå¤±: {self.best_val_loss:.6f}")
        print(f"ğŸ’¾ è¾“å‡ºæ–‡ä»¶:")
        print(f"   æœ€ä½³æ¨¡å‹: {self.output_dir}/best_model.pth")
        print(f"   è®­ç»ƒæ—¥å¿—: {self.output_dir}/training.log")
        print(f"   é…ç½®æ–‡ä»¶: {self.output_dir}/config.json")
        if self.writer:
            print(f"   TensorBoard: {self.output_dir}/tensorboard")
        print("=" * 80)
        
        self.logger.info('è®­ç»ƒå®Œæˆï¼')
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        self.save_checkpoint(epochs - 1)
        
        # ä¿å­˜è®­ç»ƒé…ç½®
        with open(self.output_dir / 'config.json', 'w') as f:
            json.dump(self.config, f, indent=2)
        
        if self.writer:
            self.writer.close()


def load_and_validate_csv_data(config):
    """åŠ è½½å’ŒéªŒè¯CSVæ•°æ®"""
    csv_path = config.get('csv_path')
    if not csv_path or not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
    
    print(f"ä» {csv_path} è¯»å–æ•°æ®...")
    df = pd.read_csv(csv_path)
    print(f"åŸå§‹æ•°æ®é›†å¤§å°: {len(df)} è¡Œ")
    
    # æ£€æŸ¥å¿…éœ€çš„åˆ—
    required_columns = config.get('required_columns', ['basename', 'folder'])
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"CSVæ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
    
    # æ£€æŸ¥å¿ƒè„åŠŸèƒ½æŒ‡æ ‡åˆ—
    cardiac_metric_columns = config.get('cardiac_metric_columns', [])
    if cardiac_metric_columns:
        missing_cardiac_columns = [col for col in cardiac_metric_columns if col not in df.columns]
        if missing_cardiac_columns:
            print(f"è­¦å‘Š: CSVæ–‡ä»¶ä¸­ç¼ºå°‘å¿ƒè„åŠŸèƒ½æŒ‡æ ‡åˆ—: {missing_cardiac_columns}")
            cardiac_metric_columns = [col for col in cardiac_metric_columns if col in df.columns]
        if cardiac_metric_columns:
            print(f"æ‰¾åˆ°å¿ƒè„åŠŸèƒ½æŒ‡æ ‡åˆ—: {cardiac_metric_columns}")
        else:
            print("æ³¨æ„: æœªæ‰¾åˆ°ä»»ä½•å¿ƒè„åŠŸèƒ½æŒ‡æ ‡æ•°æ®ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ ‡ç­¾è¿›è¡Œè®­ç»ƒæ¼”ç¤º")
    else:
        print("æ³¨æ„: é…ç½®ä¸­æœªæŒ‡å®šå¿ƒè„åŠŸèƒ½æŒ‡æ ‡åˆ—ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ ‡ç­¾è¿›è¡Œè®­ç»ƒæ¼”ç¤º")
    
    # æ•°æ®æ¸…ç†
    if config.get('remove_missing_files', True):
        initial_count = len(df)
        df = df.dropna(subset=['basename', 'folder'])
        df = df[df['basename'].notna() & df['folder'].notna()]
        if len(df) < initial_count:
            print(f"ç§»é™¤äº† {initial_count - len(df)} è¡Œç¼ºå¤±basenameæˆ–folderçš„æ•°æ®")
    
    # ç§»é™¤é‡å¤é¡¹
    if config.get('remove_duplicates', True):
        initial_count = len(df)
        df = df.drop_duplicates(subset=['basename', 'folder'])
        if len(df) < initial_count:
            print(f"ç§»é™¤äº† {initial_count - len(df)} è¡Œé‡å¤æ•°æ®")
    
    print(f"æ¸…ç†åæ•°æ®é›†å¤§å°: {len(df)} è¡Œ")
    return df, cardiac_metric_columns


def build_data_list(df, config, cardiac_metric_columns):
    """ä»DataFrameæ„å»ºæ•°æ®åˆ—è¡¨"""
    base_path = config.get('base_path', '/dataNAS/data/ct_data/ct_scans')
    data_list = []
    missing_files = []
    
    for idx, row in df.iterrows():
        basename = row['basename']
        folder = row['folder']
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        image_path_template = config.get('image_path_template', '{base_path}/stanford_{folder}/{basename}.nii.gz')
        image_path = image_path_template.format(
            base_path=base_path,
            folder=folder,
            basename=basename
        )
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if config.get('check_file_exists', False):
            if not os.path.exists(image_path):
                missing_files.append(image_path)
                continue
        
        # è·å–å¿ƒè„åŠŸèƒ½æŒ‡æ ‡æ•°æ®
        cardiac_metrics = None
        if cardiac_metric_columns:
            try:
                cardiac_metrics = []
                for col in cardiac_metric_columns:
                    value = row[col]
                    if pd.isna(value):
                        cardiac_metrics = None
                        break
                    cardiac_metrics.append(float(value))
                
                if cardiac_metrics is not None:
                    cardiac_metrics = np.array(cardiac_metrics, dtype=np.float32)
            except (ValueError, TypeError) as e:
                print(f"è­¦å‘Š: è¡Œ {idx} çš„å¿ƒè„åŠŸèƒ½æŒ‡æ ‡æ•°æ®æ— æ•ˆ: {e}")
                cardiac_metrics = None
        
        # æ”¶é›†å…¶ä»–å…ƒæ•°æ®
        metadata = {}
        metadata_columns = config.get('metadata_columns', [])
        for col in metadata_columns:
            if col in row and pd.notna(row[col]):
                metadata[col] = row[col]
        
        data_item = {
            'image': image_path,
            'cardiac_metrics': cardiac_metrics,
            'patient_id': row.get('patient_id', basename),
            'basename': basename,
            'folder': folder,
            'metadata': metadata
        }
        
        data_list.append(data_item)
    
    print(f"æˆåŠŸæ„å»º {len(data_list)} ä¸ªæ•°æ®é¡¹")
    
    if missing_files and config.get('check_file_exists', False):
        print(f"è­¦å‘Š: æœ‰ {len(missing_files)} ä¸ªæ–‡ä»¶ä¸å­˜åœ¨")
        if len(missing_files) <= 5:
            print("ç¼ºå¤±çš„æ–‡ä»¶:")
            for f in missing_files:
                print(f"  {f}")
        else:
            print(f"å‰5ä¸ªç¼ºå¤±çš„æ–‡ä»¶:")
            for f in missing_files[:5]:
                print(f"  {f}")
    
    return data_list


def split_data(data_list, config):
    """åˆ†å‰²æ•°æ®ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†"""
    split_method = config.get('split_method', 'random')
    split_ratio = config.get('train_val_split', 0.8)
    random_state = config.get('seed', 42)
    
    if split_method == 'random':
        # éšæœºåˆ†å‰²
        train_data, val_data = train_test_split(
            data_list, 
            train_size=split_ratio, 
            random_state=random_state,
            shuffle=True
        )
    elif split_method == 'sequential':
        # é¡ºåºåˆ†å‰²
        split_idx = int(len(data_list) * split_ratio)
        train_data = data_list[:split_idx]
        val_data = data_list[split_idx:]
    elif split_method == 'patient_based':
        # åŸºäºæ‚£è€…IDçš„åˆ†å‰²ï¼ˆé¿å…åŒä¸€æ‚£è€…çš„æ•°æ®å‡ºç°åœ¨è®­ç»ƒå’ŒéªŒè¯é›†ä¸­ï¼‰
        patient_ids = list(set([item['patient_id'] for item in data_list]))
        train_patients, val_patients = train_test_split(
            patient_ids,
            train_size=split_ratio,
            random_state=random_state,
            shuffle=True
        )
        
        train_data = [item for item in data_list if item['patient_id'] in train_patients]
        val_data = [item for item in data_list if item['patient_id'] in val_patients]
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®åˆ†å‰²æ–¹æ³•: {split_method}")
    
    print(f"æ•°æ®åˆ†å‰²å®Œæˆ:")
    print(f"  è®­ç»ƒé›†: {len(train_data)} ä¸ªæ ·æœ¬")
    print(f"  éªŒè¯é›†: {len(val_data)} ä¸ªæ ·æœ¬")
    
    return train_data, val_data


def create_data_loaders(config):
    """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
    # åŠ è½½å’ŒéªŒè¯CSVæ•°æ®
    df, cardiac_metric_columns = load_and_validate_csv_data(config)
    
    # æ„å»ºæ•°æ®åˆ—è¡¨
    data_list = build_data_list(df, config, cardiac_metric_columns)
    
    if not data_list:
        raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„æ•°æ®é¡¹")
    
    # åˆ†å‰²æ•°æ®
    train_data, val_data = split_data(data_list, config)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = CardiacDataset(
        train_data, 
        cardiac_metric_columns=cardiac_metric_columns
    )
    
    val_dataset = None
    if val_data:
        val_dataset = CardiacDataset(
            val_data, 
            cardiac_metric_columns=cardiac_metric_columns
        )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config.get('batch_size', 4),
        shuffle=True,
        num_workers=config.get('num_workers', 4),
        pin_memory=True,
        drop_last=True  # è®­ç»ƒæ—¶å¿…é¡»è®¾ç½®ä¸ºTrueï¼Œé¿å…BatchNormé”™è¯¯
    )
    
    val_loader = None
    if val_dataset:
        val_loader = DataLoader(
            val_dataset,
            batch_size=config.get('batch_size', 4),
            shuffle=False,
            num_workers=config.get('num_workers', 4),
            pin_memory=True,
            drop_last=False
        )
    
    # ä¿å­˜æ•°æ®ç»Ÿè®¡ä¿¡æ¯
    data_info = {
        'total_samples': len(data_list),
        'train_samples': len(train_data),
        'val_samples': len(val_data) if val_data else 0,
        'cardiac_metric_columns': cardiac_metric_columns,
        'split_method': config.get('split_method', 'random'),
        'split_ratio': config.get('train_val_split', 0.8)
    }
    
    # ä¿å­˜åˆ°è¾“å‡ºç›®å½•
    output_dir = Path(config['output_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)
    with open(output_dir / 'data_info.json', 'w', encoding='utf-8') as f:
        json.dump(data_info, f, indent=2, ensure_ascii=False)
    
    return train_loader, val_loader


 
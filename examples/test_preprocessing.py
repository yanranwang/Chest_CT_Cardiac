#!/usr/bin/env python3
"""
æ•°æ®é¢„å¤„ç†æµ‹è¯•è„šæœ¬

è¯¥è„šæœ¬å¸®åŠ©ç”¨æˆ·é€æ­¥æµ‹è¯•æ•°æ®é¢„å¤„ç†ç³»ç»Ÿï¼Œç¡®ä¿ç³»ç»Ÿåœ¨å¤„ç†å¤§é‡æ•°æ®ä¹‹å‰èƒ½å¤Ÿæ­£å¸¸å·¥ä½œã€‚

ä½¿ç”¨æ–¹æ³•:
    python test_preprocessing.py
"""

import os
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from merlin.training.data_preprocessor import DataPreprocessor
from merlin.training.cardiac_trainer import load_and_validate_csv_data, build_data_list


def test_single_item():
    """æµ‹è¯•å•ä¸ªæ•°æ®é¡¹çš„å¤„ç†"""
    print("ğŸ§ª æµ‹è¯•1ï¼šå•ä¸ªæ•°æ®é¡¹å¤„ç†")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config_path = Path(__file__).parent / 'config_fast_training.json'
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # è®¾ç½®æµ‹è¯•è¾“å‡ºç›®å½•
    config['output_dir'] = 'outputs/test_preprocessing'
    
    try:
        # åŠ è½½æ•°æ®
        print("ğŸ“‚ åŠ è½½æ•°æ®...")
        df, cardiac_metric_columns = load_and_validate_csv_data(config)
        data_list = build_data_list(df, config, cardiac_metric_columns)
        
        if not data_list:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®")
            return False
        
        # é€‰æ‹©ç¬¬ä¸€ä¸ªæ•°æ®é¡¹
        test_item = data_list[0]
        print(f"ğŸ“„ æµ‹è¯•æ•°æ®é¡¹: {test_item['basename']}")
        print(f"ğŸ“ å›¾åƒè·¯å¾„: {test_item['image']}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(test_item['image']):
            print(f"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {test_item['image']}")
            return False
        
        # åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = DataPreprocessor(config)
        
        # å¤„ç†å•ä¸ªæ•°æ®é¡¹
        print("ğŸ”„ å¼€å§‹å¤„ç†...")
        result = preprocessor.preprocess_single_item(test_item)
        
        if result:
            item_id, storage_data = result
            print(f"âœ… å¤„ç†æˆåŠŸ!")
            print(f"   æ•°æ®ID: {item_id}")
            print(f"   å›¾åƒå½¢çŠ¶: {storage_data['processed_shape']}")
            print(f"   æ•°æ®ç±»å‹: {storage_data['data_type']}")
            return True
        else:
            print("âŒ å¤„ç†å¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_small_batch():
    """æµ‹è¯•å°æ‰¹é‡æ•°æ®å¤„ç†"""
    print("\nğŸ§ª æµ‹è¯•2ï¼šå°æ‰¹é‡æ•°æ®å¤„ç†")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config_path = Path(__file__).parent / 'config_fast_training.json'
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # è®¾ç½®æµ‹è¯•é…ç½®
    config['output_dir'] = 'outputs/test_preprocessing'
    config['preprocess_batch_size'] = 4
    config['enable_multiprocessing'] = False
    
    try:
        # åŠ è½½æ•°æ®
        print("ğŸ“‚ åŠ è½½æ•°æ®...")
        df, cardiac_metric_columns = load_and_validate_csv_data(config)
        data_list = build_data_list(df, config, cardiac_metric_columns)
        
        if not data_list:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®")
            return False
        
        # é€‰æ‹©å‰10ä¸ªæ•°æ®é¡¹
        test_data = data_list[:10]
        print(f"ğŸ“„ æµ‹è¯•æ•°æ®é¡¹æ•°é‡: {len(test_data)}")
        
        # åˆ›å»ºé¢„å¤„ç†å™¨
        preprocessor = DataPreprocessor(config)
        
        # å¤„ç†å°æ‰¹é‡æ•°æ®
        print("ğŸ”„ å¼€å§‹å¤„ç†...")
        preprocessor.preprocess_data(test_data, force_reprocess=True)
        
        # éªŒè¯ç»“æœ
        hdf5_path = Path(config['output_dir']) / 'preprocessed_data.h5'
        if hdf5_path.exists():
            print(f"âœ… é¢„å¤„ç†å®Œæˆ!")
            print(f"   HDF5æ–‡ä»¶å¤§å°: {hdf5_path.stat().st_size / (1024*1024):.2f} MB")
            return True
        else:
            print("âŒ é¢„å¤„ç†å¤±è´¥ï¼šæœªç”ŸæˆHDF5æ–‡ä»¶")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("\nğŸ§ª æµ‹è¯•3ï¼šæ•°æ®åŠ è½½æµ‹è¯•")
    print("=" * 50)
    
    # åŠ è½½é…ç½®
    config_path = Path(__file__).parent / 'config_fast_training.json'
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    config['preprocessed_data_dir'] = 'outputs/test_preprocessing'
    
    try:
        from merlin.training.fast_dataloader import FastDataLoaderManager
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨ç®¡ç†å™¨
        print("ğŸ“‚ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        manager = FastDataLoaderManager(config)
        
        # è·å–æ•°æ®ç»Ÿè®¡
        stats = manager.get_data_statistics()
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»æ•°æ®é¡¹: {stats['total_items']}")
        print(f"   HDF5æ–‡ä»¶å¤§å°: {stats['hdf5_file_size_mb']} MB")
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        print("ğŸ”„ åˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        train_loader, val_loader = manager.create_data_loaders()
        
        print(f"âœ… æ•°æ®åŠ è½½å™¨åˆ›å»ºæˆåŠŸ!")
        print(f"   è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")
        print(f"   éªŒè¯é›†å¤§å°: {len(val_loader.dataset)}")
        
        # æµ‹è¯•æ•°æ®è¯»å–
        print("ğŸ”„ æµ‹è¯•æ•°æ®è¯»å–...")
        batch = next(iter(train_loader))
        print(f"âœ… æ•°æ®è¯»å–æˆåŠŸ!")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch['image'].shape[0]}")
        print(f"   å›¾åƒå½¢çŠ¶: {batch['image'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æ•°æ®é¢„å¤„ç†ç³»ç»Ÿæµ‹è¯•")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½•
    test_output = Path('outputs/test_preprocessing')
    test_output.mkdir(parents=True, exist_ok=True)
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        ("å•ä¸ªæ•°æ®é¡¹å¤„ç†", test_single_item),
        ("å°æ‰¹é‡æ•°æ®å¤„ç†", test_small_batch),
        ("æ•°æ®åŠ è½½æµ‹è¯•", test_data_loading)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ§ª å¼€å§‹æµ‹è¯•: {test_name}")
        if test_func():
            passed += 1
            print(f"âœ… {test_name} é€šè¿‡")
        else:
            print(f"âŒ {test_name} å¤±è´¥")
    
    print("\n" + "=" * 80)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥å¼€å§‹å¤„ç†å®Œæ•´æ•°æ®é›†ã€‚")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("   1. å¤„ç†å®Œæ•´æ•°æ®é›†:")
        print("      python -m merlin.training.data_preprocessor --config examples/config_fast_training.json")
        print("   2. å¦‚æœéœ€è¦å¤šè¿›ç¨‹å¤„ç†:")
        print("      python -m merlin.training.data_preprocessor --config examples/config_fast_training.json --enable_multiprocessing --num_workers 4")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®è·¯å¾„ã€‚")
        print("\nğŸ” æ•…éšœæ’é™¤:")
        print("   1. æ£€æŸ¥CSVæ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   2. æ£€æŸ¥å›¾åƒæ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
        print("   3. ç¡®è®¤æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´")
        print("   4. æ£€æŸ¥Pythonç¯å¢ƒæ˜¯å¦åŒ…å«æ‰€æœ‰å¿…éœ€çš„ä¾èµ–")


if __name__ == '__main__':
    main() 